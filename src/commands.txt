Checking SSH Keys
---------------------------------------------------
ls -al ~/.ssh


Generating SSH Keys
-------------------------------------------------------
ssh-keygen -t rsa -b 4096 -C "ishugarg567@gmail.com"
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_rsa


Setting up account on local machine
------------------------------------------------------
git config --global user.name "Ishu Garg"
git config --global user.name
git config --global user.email "ishugarg567@gmail.com"
git config --global user.email
---------------------------------------

Copyting the github project
---------------------------

git init
git add *
git commit -m "First commit"
Repo: https://github.com/ash567/guess_what.git
git remote add origin https://github.com/ash567/guess_what.git
git remote -v
git push origin master




Commands:

To clone the repo:
******************
git clone --recursive https://github.com/GuessWhatGame/guesswhat.git


To Unzip
********
unzip data/img/test2014.zip -d data/img/raw

To install
**********
pip install \
    tensorflow\
    nltk \
    tqdm \
    image


Before running code print

export PYTHONPATH=src:${PYTHONPATH} 

Making coco api


------------------------------

Remember to have init python file in each directory so as to import the module
Also define the python paths to be src


0
down vote
You cannot pickle instance methods using the multiprocessing package in python. Instance methods aren't listed in the pickling documentation.

If you don't mind using an external library, you can look at multiprocess, which is a drop-in replacement for python's multiprocessing. To make use of the library, you would do the following:

pip install multiprocess
replacefrom multiprocessing import Pool, TimeoutError, cpu_count with
from multiprocess import Pool, TimeoutError, cpu_count
I have tested your example on my machine and it actually executes using multiprocess.
-------------------------

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)


It was due to large batch size. Memory issues.
-------------------------------------
creating dictionary
python src/guesswhat/preprocess_data/create_dictionary.py -data_dir data -dict_file dict.json -min_occ 3

----------------------------------------------
training questioner

python src/guesswhat/train/train_qgen_supervised.py \
   -data_dir data \
   -img_dir data/img/ft_vgg_img \
   -config config/qgen/config.json \
   -exp_dir out/qgen \
   -no_thread 2 \
   -gpu_ratio 0.0

    parser.add_argument("-img_dir", type=str, help='Directory with images')
    parser.add_argument("-load_checkpoint", type=str, help="Load model parameters from specified checkpoint")
    parser.add_argument("-continue_exp", type=bool, default=False, help="Continue previously started experiment?")
---------------------------
array=( crop )
for mode in "${array[@]}"; do
   python src/guesswhat/preprocess_data/extract_img_features.py \
     -img_dir data/img/raw \
     -data_dir data \
     -out_dir data/img/ft_vgg_$mode \
     -network vgg \
     -ckpt data/vgg_16.ckpt \
     -feature_name fc8 \
     -mode $mode \
     -gpu_ratio 0.0 \
     -batch_size 4 \
     -no_thread 4
done
